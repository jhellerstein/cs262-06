<!DOCTYPE html PUBLIC "-//w3c//dtd html 4.0 transitional//en"><html><head>         <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">         <meta name="Author" content="Joseph M. Hellerstein">         <meta name="GENERATOR" content="Mozilla/4.75 [en] (WinNT; U) [Netscape]">  <title>The Postgres Storage Manager</title>        <meta name="author" content="Joe Hellerstein"></head>  <body>  &nbsp; <table border="0" cols="2" width="100%">  <tbody>     <tr>  <td><b>Advanced Topics in Computer Systems</b></td>   <td>             <div align="Right"><b>Fall, 2005<br>      </b>  </div>       </td>     </tr>     <tr>       <td><b>Joe Hellerstein &amp; Timothy Roscoe</b><br>       </td>       <td><br>       </td>     </tr>     </tbody> </table>   <h2> POSTGRES Storage System</h2>  An extremely simple solution to the complex recovery problem.  <p><b>History:</b> </p> <ul>  <li> POSTGRES storage system (Stonebraker) discussed in Berkeley Tech Reports from 1985</li>   <li> LFS (Ousterhout &amp; Douglis) discussed in Berkeley Tech Reports from 1988</li>   <li> I have been assured that the two had little or nothing to do with each other</li>       <ul>  <li> though Stonebraker is thanked in the "Beating the I/O Bottleneck"TR from 1988</li>      </ul>   <li> Was it the Peet's Coffee?</li>  </ul>  <b>POSTGRES Overview</b> <ul>  <li> Followon to INGRES</li>   <li> The prototype for "Object-Relational" databases, but had many other interesting goals as well!</li>       <ul>  <li> extensible OO types (and methods -- i.e. download code into the DBMS)</li>   <li> extensible access methods</li>   <li> "active" database (triggers and rules)</li>   <li> a novel storage manager</li>   <li> parallel query processing (XPRS: eXtended Postgres on RAID and Sprite)</li>      </ul>   <li> A second system</li>       <ul>  <li> The extensibility features worked, and were extremely influentialin research and industry</li>   <li> The active DB stuff mostly worked, and had significant impact</li>   <li> The XPRS parallel query optimization stuff was influential on later designs, though the code didn't go anywhere.   <li> The storage manager worked slowly, and the design has had little impact.</li>    <ul>  <li> "When considering the POSTGRES storage system, we were guided by a missionary zeal to do something different"</li>   <li> Still, interesting to discuss.</li>    </ul>      </ul>  </ul>  <b>Problem:</b> <ul>  <li> WAL recovery code is really complicated (witness ARIES)</li>   <li> recovery code must be flawless</li>   <li> failures can be arbitrary &#8211; testing is hard to pull off</li>  </ul>  What&#8217;s wrong with this picture?  <pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ________________<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; |&nbsp;&nbsp;&nbsp;&nbsp; DBMS&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; |<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ----------------<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -----&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -----<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; DB&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Log<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -----&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -----</pre>   <p><br> <b>Alternative</b>: A no-overwrite storage system. </p> <ol>  <li> Time travel comes for free</li>   <li> instantaneous recovery</li>   <li> no crash recovery code</li>  </ol>  <b>Details</b> <ul>  <li> Life of a xact:</li>       <ul>  <li> increment and grab current global XID</li>   <li> do processing</li>   <li> change status to committed in log (more on this below)</li>   <li> FORCE data &amp; log to stable storage (in that order!)</li>      </ul>   <li> There is a "log" of sorts:</li>  </ul>   <ul>      <ul>  <li> tail of log (oldest active xact to present) needs 2 bits per transaction to record state (committed, aborted, in progress)</li>   <li> body of log needs only 1 bit per xact (committed or aborted)</li>   <li> at 1 xact per second, 1 year of transactions fits in 4Mb log space!</li>   <li> Detail: if this is still too big, use a Bloom filter to represent aborted xacts (lossy compression)</li>   <li> with just a little NVRAM, the log essentially never needs forcing</li>      </ul>  </ul>  Each tuple has a bunch of system fields:  <ul>  <li> OID: a database-wide unique ID across all time</li>   <li> Xmin: XID of inserter</li>   <li> Tmin: commit time of Xmin</li>   <li> Cmin: command ID of inserter</li>   <li> Xmax: XID of deleter (if any)</li>   <li> Tmax: commit time of Xmax (if any)</li>   <li> Cmax: command ID of deleter (if any)</li>   <li> PTR: pointer to chain of deltas</li>  </ul>  Updates work as follows:  <ol>  <li> Xmax &amp; Cmax set to updater&#8217;s XID</li>   <li> new replacement tuple appended to DB with:</li>  </ol>   <ul>      <ul>  <li> OID of old record</li>   <li> Xmin &amp; Cmin = XID of updater</li>   <li> in fact, store this as delta off original tuple</li>      </ul>  </ul>  Deleters simply set Xmax &amp; Cmax to their XID  <p>The first version of a record is called the Anchor Point, which has a chainof associated delta record </p> <p>"Hopefully", delta records fit on the same page as their anchor point. </p> <ul>  <li> Obvious optimization for read-intensive workloads?</li>  </ul>   <h3> CC, Timestamps, Archiving:</h3>  If we actually got timestamps at xact start, we&#8217;d get timestamp ordering CC.  <P>An aside: timestamp and multi-version concurrency control.  See <a href="http://portal.acm.org/citation.cfm?id=356846">Bernstein and Goodman's survey</a> for a more complete presentation.<ol><li><B>TSCC</B><ul><li>Assign each transaction Ti a timestamp ts(Ti) at start time.</li><li>Each tuple t is associated with a Read Timestamp R-ts(t) and a Write TS W-ts(t)</li><li>To read a tuple t, xact T1 must ensure that W-ts(t) &le; ts(T1); else abort T1 (why?).  Update tuple and set R-ts(t)=MAX(R-ts(t), TS(T1)).   Hence invariant: RTS is <i>latest</i> reader of this version.</li><li>To write a tuple t, xact T2 must ensure that R-ts(t)&le; ts(T2); else abort T2 (why?). Then update tuple and set W-ts(t)=MAX(W-ts(t),ts(T1))</li><li>A bummer: only one equivalent serial schedule, based on xact start times!  Severely diminished concurrency opportunities (when does a transaction get to commit?).  Can ameliorate somewhat by buffering transactions' intentions, picking their admission times, and then really running them.  Is that practical?	<li>Another bummer: read-only transactions require updates to timestamps, and hence must do synchronous I/O before commit!  As a rule, it's bad to turn reads into writes.</li></ul><li><B>MVCC</B><ul><li>As in TSCC, assign timestamps to transactions and tuples.</li><li>To write a tuple t, xact T1 creates a new version with W-ts(t)=ts(T1)</li><li>To read a tuple t, xact T2 chooses version of t with largest W-ts(t) s.t. W-ts(T) &le; ts(T2).  Set R-ts(t)=MAX(R-ts(t), ts(T2)). Hence invariant: RTS is <i>latest</i> reader of this version</li>   <li>Careful: what if a writer's TS falls between the W-ts and R-ts of a version? Then the reader should have seen this writer's version but didn't!  Writer must abort and restart.  (Hence the invariant on latest R-ts).</li> <li>Note that read-only xacts never restart, which is nice.</li><li>Similar concurrency issues due to timestamping.</li></ul></ol></p><p>Now, back to Postgres.  We will read that restart-oriented CC is usually a loser to blocking-based CC.  So Postgres chose to do 2PL for concurrency, even though it has versions for recover.  Also, get timestamp at commit time, not start time! </p> <p>How to set Tmin and Tmax if you don&#8217;t have the commit time? </p> <ul>  <li> XID is taken as an oid from the TIME relation</li>   <li> at commit:</li>       <ul>  <li> update your appropriate TIME tuple with the wall-clock time.</li>   <li> then force data pages to stable storage, change status to committed in tail of log</li><li>Why are we not worried about aborting, as in MVCC?</li>      </ul>   <li> 3 levels of archiving</li>  </ul>   <ol>      <ol>  <li> no archive: old versions not needed</li>   <li> light archive: old versions not to be accessed often</li>   <li> heavy archive: old versions to be accessed regularly</li>      </ol>  </ol>   <ul>  <li> on first access to a tuple from a "heavy archive" relation, you update the OIDs in Tmin and Tmax with values from the TIME relation</li>  </ul>   <h3> Time Travel</h3>  Allows queries over a table as of some wall-clock time in the past.  <p>Rewrite queries to handle the system fields in tuples </p> <p>Reading a Record: get record, follow delta chain until you&#8217;ve got theappropriate version constructed. </p> <p>Indexes all live on disk.  They contain entries (anchor pointers) for all versions. The actual index blocks do experience overwrites.</p> <h3> Archiving</h3>   <ul>  <li> historical data can be forced to archive via the vacuum cleaner</li>  </ul>   <ol>      <ol>  <li> write archive record(s)</li>   <li> write new anchor record</li>   <li> reclaim space of old anchor/deltas</li>      </ol>  </ol>   <ul>  <li> crash during vacuum?</li>       <ul>  <li> indexes may lose archive records, though Seq. Scan will always work</li>   <li> duplicate records may be forced to archive or may co-exist in archive and in live DB: OK because POSTGRES doesn&#8217;t do multisets</li>      </ul>   <li> Can build R-trees over lifetime intervals of data on archive</li>  </ul>   <h3> "Performance Comparison" vs. WAL</h3>  <b>Tech trends discussion</b><ul><li>CPU speed scales with Moore's Law</li><li>Disk density ($$/MB) scales with Moore's Law</li> <li>Disk "speed" (what does this mean?) is improving slowly.</li><li>Hence you'll always be able to buy CPUs to keep up with your disk speeds, and you'll never be CPU-bound..</li><li> What do you make of this analysis?</li></ul>  <b>Assumptions:</b> <ul>  <li> records fit on a single page</li>   <li> deltas live on the same page as anchors</li>   <li> single-record xacts</li>   <li> update-only workload (?!)</li>  </ul>  NVRAM required to make POSTGRES compete on even this benchmark.  <h3>The Real POSTGRES Storage Manager Story</h3> <ul>   <li> Tuple differencing wasn't implemented</li>   <li> R-trees over archive not used</li>   <li> Stonebraker commercialized POSTGRES at Illustra</li>   <li> Illustra never claimed to be a TP competitor</li>   <li> Informix bought Illustra, and replaced the no-overwrite storage manager with Informix&#8217;s WAL</li>   <li>IBM bought Informix.<br>  <li> PostgreSQL now uses a WAL recovery scheme, and ditched time travel.    Rationalized vacuum accordingly.  However, maintained version metadata and implemented MVCC!</li>   </li>  </ul>  <b>Ask Not What POSTGRES Can Do For You...</b> <ul>  <li> If you did made a handful of obvious design changes to POSTGRES, would it be viable today?</li>       <ul>  <li> Could certainly be made better</li>   <li> CS262 project there</li>      </ul>   <li> What if you throw in:</li>       <ul>  <li> a little NVRAM</li>   <li> flush to remote memory in a cluster</li>   <li> variable-sized storage units</li>   <li> limited time travel</li>      </ul>   <li> The Telegraph Storage manager was marching down this path...</li>       <ul>  <li> nice cs262 project</li>      </ul>  </ul>   </body></html>